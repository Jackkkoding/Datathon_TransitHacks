---
title: "Machine Learning_MP4"
author: "Dizhe Xia"
date: "2025/3/12"
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
output:
  echo: false
  eval: true
---

# 1.

```{python}

import pandas as pd

df_vote = pd.read_csv('vote.csv')
df_work = pd.read_csv('work.csv')

# Print data types for each variable in df_vote dataset
print("Data Types in df_vote Dataset:")
print(df_vote.dtypes)

# Print data types for each variable in df_work dataset
print("Data Types in df_work Dataset:")
print(df_work.dtypes)

```

# 2

## (a)
```{python}

# Convert target variable 'vote' to binary form (0 and 1)
df_vote['vote'] = df_vote['vote'].map({'vote': 1, 'did not vote': 0})

# Convert target variable 'work' to binary form (0 and 1)
df_work['work'] = df_work['work'].map({'flexible': 1, 'not flexible': 0})

print("Data Types in df_vote Dataset:")
print(df_vote.dtypes)

print("Data Types in df_work Dataset:")
print(df_work.dtypes)
```


## (b)
```{python}

# Categorical variables to compare
categorical_vars = ['pesex', 'ptdtrace', 'pehspnon', 'prcitshp', 'peeduca']

# Compare categories in categorical variables between datasets
for var in categorical_vars:
    categories_vote = set(df_vote[var].unique())
    categories_work = set(df_work[var].unique())
    discrepancies = categories_vote.symmetric_difference(categories_work)

    print(f"Variable: {var}")
    if discrepancies:
        print(f"  Discrepancies found: {discrepancies}")
    else:
        print("  No discrepancies found.")

```

## (c)
```{python}

# Combine datasets temporarily to ensure consistent one-hot encoding
combined_df = pd.concat([df_vote[categorical_vars], df_work[categorical_vars]], keys=['vote', 'work'])
combined_df_encoded = pd.get_dummies(combined_df, columns=categorical_vars)

# Separate datasets back into original sets with one-hot encoding applied
df_vote_encoded = combined_df_encoded.loc['vote']
df_work_encoded = combined_df_encoded.loc['work']

# Verify results
print("df_vote encoded shape:", df_vote_encoded.shape)
print("df_work encoded shape:", df_work_encoded.shape)

```

## (d)

```{python}

# Apply one-hot encoding separately
df_vote_encoded = pd.get_dummies(df_vote, columns=categorical_vars)
df_work_encoded = pd.get_dummies(df_work, columns=categorical_vars)

# Identify missing columns after encoding
missing_cols_in_vote = set(df_work_encoded.columns) - set(df_vote_encoded.columns)
missing_cols_in_work = set(df_vote_encoded.columns) - set(df_work_encoded.columns)

# Add missing columns with zeros to ensure consistent structure
for col in missing_cols_in_vote:
    df_vote_encoded[col] = 0

for col in missing_cols_in_work:
    df_work_encoded[col] = 0

# Ensure column order is consistent
df_vote_encoded = df_vote_encoded.reindex(sorted(df_vote_encoded.columns), axis=1)
df_work_encoded = df_work_encoded.reindex(sorted(df_work_encoded.columns), axis=1)

# Verify results
print("df_vote encoded columns:", df_vote_encoded.columns)
print("df_work encoded columns:", df_work_encoded.columns)

```

## (e)

```{python}

from sklearn.preprocessing import MinMaxScaler

categorical_vars = ['pesex', 'ptdtrace', 'pehspnon', 'prcitshp', 'peeduca']

# Apply one-hot encoding separately
df_vote_encoded = pd.get_dummies(df_vote, columns=categorical_vars, dtype=int)
df_work_encoded = pd.get_dummies(df_work, columns=categorical_vars, dtype=int)

# Align the columns to have consistent structure
df_vote_encoded, df_work_encoded = df_vote_encoded.align(df_work_encoded, join='outer', axis=1, fill_value=0)

df_vote_encoded['prtage'] = df_vote['prtage']
df_vote_encoded['vote'] = df_vote['vote']

df_work_encoded['prtage'] = df_work['prtage']
df_work_encoded['work'] = df_work['work']

# Scale continuous variables using MinMaxScaler

scaler = MinMaxScaler()
df_work_encoded[['prtage']] = scaler.fit_transform(df_work_encoded[['prtage']])
df_vote_encoded[['prtage']] = scaler.transform(df_vote_encoded[['prtage']])

```

Scaling continuous predictors ensures all features contribute proportionally and prevents predictors with larger scales from disproportionately influencing the SVM classifier, thereby improving the performance and accuracy of the model.

# 3

```{python}
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score

# Define predictors and target for df_work dataset
X_work = df_work_encoded.drop(columns=['work'])
y_work = df_work_encoded['work']

# Define hyperparameters
C_values = [0.1, 1, 5, 10]
kernels = ['linear', 'poly', 'rbf']

# Perform cross-validation and report error rates
for C in C_values:
    for kernel in kernels:
        svm_model = SVC(C=C, kernel=kernel, random_state=26)
        scores = cross_val_score(svm_model, 
                                 X=X_work, 
                                 y=y_work, 
                                 cv=5, 
                                 scoring='accuracy')
        error_rate = 1 - scores.mean()
        print(f'C: {C}, Kernel: {kernel}, Cross-Validation Error Rate: {error_rate:.4f}')


```

# 4.

The combination of hyperparameters that minimizes the 5-fold cross-validation error rate is:

- **Cost (C)**: 0.1  

- **Kernel**: Linear  

- **Cross-validation error rate**: 0.1398


# 5.

```{python}

from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_work, y_work, random_state=26)

# Train the best SVM classifier
svm_best_model = SVC(C=0.1, kernel='linear', random_state=26)
svm_best_model.fit(X_train, y_train)

# Predict on test set and calculate accuracy
predictions = svm_best_model.predict(X_test)
accuracy = accuracy_score(y_test, predictions)

print(f"Accuracy of the SVM classifier on df_work data: {accuracy:.4f}")


```

# 6.

```{python}

X_work = df_work_encoded.drop(columns=['work'])
y_work = df_work_encoded['work']

# Predict work flexibility for df_vote dataset using trained SVM model
svm_best_model = SVC(C=0.1, kernel='linear', random_state=26, class_weight='balanced')
svm_best_model.fit(X_work, y_work)

X_vote = df_vote_encoded[X_work.columns]
df_vote_encoded['imputed_work'] = svm_best_model.predict(X_vote)

# Compute and report summary statistics for the imputed flexible work measure
print(df_vote_encoded['imputed_work'].describe())


```

# 7.

```{python}
import statsmodels.api as sm

# Add age squared to df_vote_encoded dataset
df_vote_encoded['age_squared'] = df_vote_encoded['prtage'] ** 2

# Prepare predictors for logistic regression
predictors = ['imputed_work', 'prtage', 'age_squared', 'pesex_FEMALE']
X = df_vote_encoded[predictors]
y = df_vote_encoded['vote']

# Add constant to predictors for the intercept
X = sm.add_constant(X)

# Fit logistic regression model
logit_model = sm.Logit(y, X)
result = logit_model.fit()

# Output regression results
print(result.summary2())
```

1. **Imputed Work Schedule (`imputed_work`)**:  
   The coefficient is small (0.0188) and statistically insignificant (p=0.894), indicating that the flexibility of work schedules (as predicted by the SVM model) does **not significantly influence** an individual's likelihood to vote in this dataset.  
   This finding challenges the initial hypothesis that flexible working hours may facilitate higher voter turnout.

2. **Age (`prtage`) and Age Squared (`age_squared`)**:  
   Both age terms have negative and highly significant coefficients (p<0.001). This indicates a nonlinear relationship between age and voting probability:

   - Younger and older individuals may have different voting probabilities.

   - Given that both age and age squared coefficients are negative, voting likelihood is highest among mid-aged voters and lower among younger and older age groups, forming an inverted U-shaped relationship.

3. **Gender (`pesex_FEMALE`)**:  
   The negative coefficient (-0.1497) is marginally significant (p=0.089). This suggests a weak trend that females may have a slightly lower likelihood of voting compared to males, although the evidence is not strong enough to conclusively state this difference.

## Interpretation

- **Work flexibility (policy implication)**:  
  The insignificant result for `imputed_work` implies that policies aimed solely at increasing work schedule flexibility might not substantially impact voter turnout, at least as predicted by this analysis.

- **Age (demographic implication)**:  
  Age is a strong predictor of voting behavior, with a clear nonlinear pattern. Policy efforts or outreach campaigns should consider targeting younger or older groups specifically, as mid-age groups already appear to have higher participation.

- **Gender (societal implication)**:  
  The marginal significance related to gender suggests the need for further investigation. While there's a hint of potential gender-based differences in voting, further analysis or data collection might clarify this relationship.


# 8.

```{python}

# Compute proportion of imputed work schedules labeled as "flexible"
a = df_vote_encoded['imputed_work'].mean()
print(f"Proportion of imputed flexible work schedules (a): {a:.4f}")

# Cross-validation error rate obtained from Q3
b = 0.1398
print(f"Cross-validation error rate (b): {b:.4f}")

# Define function M(a, b) based on the given formula
def compute_M(a, b):
    term1 = (1 - b) * b / a
    term2 = (1 - b) * b / (1 - a)
    M = (1 / (1 - 2 * b)) * (1 - term1 - term2)
    return M

# Compute M(a, b) using values calculated above
M_ab = compute_M(a, b)

print(f"Scaling function value M(a, b): {M_ab:.4f}")

```


# 9.


The logistic regression coefficient for the imputed work schedule (`imputed_work`) needs to be corrected by dividing it by the scaling factor **M(a,b)** computed previously. 

The original coefficient for `imputed_work` is **0.0188**. Given scaling factor **M(a,b)** is less than 1 (e.g., approximately **0.7203**), dividing the original estimate by **M(a,b)** will yield a **larger corrected coefficient**:

$$
\text{Corrected coefficient} = \frac{0.0188}{0.7203} \approx 0.0261
$$

### Interpretation of the correction:

- **Larger or Smaller?**  
  The corrected coefficient (0.0261) is larger than the original coefficient (0.0188).
   Attenuation bias due to measurement error typically biases estimates toward zero, so correcting for it usually increases the magnitude of the estimate.

- **Does it change previous result?**  
  Despite this correction, the coefficient remains very small and is unlikely to become statistically or substantively significant. Therefore, while the bias correction slightly adjusts the magnitude of the estimate, it **does not meaningfully change the previous interpretation**:  
  **Work flexibility remains an insignificant predictor of voting behavior.**

Therefore, the bias-correction clarifies the magnitude of the estimate but does not alter the overall conclusion of the analysis.
